---
title: "数字海南 实习第四天上午"
gitinfo: true
share: true
comments: true
slug: "7"
images: ["https://github.com/Borber/PublicPic1/blob/master/ST/2x.jpg"] 
description: "封锁IP段反爬虫的网站就是屑!"
tags: ["爬虫", "Scrapy", "python"]
date: 2020-08-06T14:16:04+08:00
---

最后还是知道了 , 不是环境的问题,就是主机的IP是阿里云的网段, 然后被网站封了, 返回的结果是,xml 以及网络环境未知的文字. 导致的base64解码失败. 不是本身程序的问题. 妈的… 真的就是屑 害我折腾了一上午. 然后写了个代理池也没用上. 运维直接就帮忙把IP换了就可以了. 哎, 基本就是浪费了一上午的时间. 中午吃饭也吃的晚.

中间环境配置的时候, 也出现了 Scrapy 的一个依赖装不上… 妈的 最后很蛋疼的单独装这个包 再装Scrapy 就可以了. 我真的是无语了.垃圾python 毁我青春.

然后爬虫现在是搞定了, 放在主机上慢慢跑去吧. 然后在还没写完爬虫的时候帆哥布置新的任务了 感觉不是太难, 相当于一个java小爬虫, 然后实现一个api 发送一个数字, 返回一串json? 应该是吧. 还没有仔细看呢 感觉也是用不了多久就能解决.

对了, 下午该去找帆哥拿个插座了. 小鱼姐给的大屏幕还没有用上呢. emmm 我也不知道为啥只有一个插板有用, 

昨晚睡得有点晚, 不过一上午都在干活, 还是很憋屈的干活, 所以也感觉到困. 总之我是那种一集中注意力就必须完成的人. 只有了却心中这个念想, 才有心情和动力去干别的. 

下午先确定好Java项目的技术栈吧. 希望不要是我完全没有接触过的. 第一次和别人合作开发项目(以前的期末项目不能算合作吧, 基本就是我一个人完成的)

十分期待

